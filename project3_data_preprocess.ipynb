{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from datetime import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this work, I first import and analyze data from Google browsing, Fitbit, Strava, Instagram, and LinkedIn, and then will use it all together for some correlations\n",
    "# Then look at how it changes during different life events\n",
    "# This specific file just gets all the data and merges it into 1 csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Browsing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_data(type_data):\n",
    "    file_in = f'./Takeout_{type_data}/Chrome_{type_data}/History.json'\n",
    "    with open(file_in, \"r\", encoding=\"utf-8\") as f:\n",
    "        google_data = json.load(f)\n",
    "\n",
    "    browser_history = google_data.get(\"Browser History\", []) \n",
    "\n",
    "    # Convert JSON to DataFrame\n",
    "    google_df = pd.DataFrame(browser_history)\n",
    "\n",
    "    # Convert time from microseconds to standard datetime\n",
    "    google_df[\"datetime\"] = pd.to_datetime(google_df[\"time_usec\"] // 1_000_000, unit=\"s\")\n",
    "    google_df = google_df[[\"datetime\", \"title\", \"url\"]]\n",
    "    print(google_df.head(2))\n",
    "\n",
    "    # Find the first and last date!\n",
    "    first_date = google_df[\"datetime\"].min()\n",
    "    last_date = google_df[\"datetime\"].max()\n",
    "\n",
    "    print(f\"First recorded browsing activity for {type_data}: {first_date}\")\n",
    "    print(f\"Last recorded browsing activity for {type_data}: {last_date}\")\n",
    "\n",
    "    # google searches vs other browsing\n",
    "    # Create a new column to classify searches\n",
    "    google_df[\"is_google_search\"] = google_df[\"title\"].str.contains(\"- Google Search\", na=False)\n",
    "\n",
    "    # Count searches vs. other browsing\n",
    "    search_count = google_df[\"is_google_search\"].sum()\n",
    "    other_count = len(google_df) - search_count\n",
    "\n",
    "    print(f\"Total Google Searches for {type_data}: {search_count}\")\n",
    "    print(f\"Total Other Browsing for {type_data}: {other_count}\")\n",
    "\n",
    "    # Visualization\n",
    "    counts = [search_count, other_count]\n",
    "    labels = [\"Google Searches\", \"Other Browsing\"]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(labels, counts)\n",
    "    plt.xlabel(\"Activity Type\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Google Searches vs. Other Browsing for {type_data}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Total the number of sites visited per day\n",
    "    daily_site_visits = google_df.groupby(google_df[\"datetime\"].dt.date).size()\n",
    "\n",
    "    # Plot the time series of daily site visits\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(daily_site_visits.index, daily_site_visits.values, marker=\"o\", linestyle=\"-\", label=\"Sites Visited\")\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Number of Sites Visited\")\n",
    "    plt.title(f\"Daily Number of Sites Visited Over Time for {type_data}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Find the number of sites visited per day\n",
    "    daily_site_visits = google_df.groupby(google_df[\"datetime\"].dt.date).size()\n",
    "\n",
    "    # Find the number of Google searches per day\n",
    "    daily_google_searches = google_df[google_df[\"is_google_search\"]].groupby(google_df[\"datetime\"].dt.date).size()\n",
    "\n",
    "    # Calc statistics\n",
    "    avg_sites_per_day = daily_site_visits.mean()\n",
    "    std_sites_per_day = daily_site_visits.std()\n",
    "    avg_google_searches_per_day = daily_google_searches.mean()\n",
    "    std_google_searches_per_day = daily_google_searches.std()\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Average number of sites visited per day for {type_data}: {avg_sites_per_day:.2f}\")\n",
    "    print(f\"Standard deviation of sites visited per day for {type_data}: {std_sites_per_day:.2f}\")\n",
    "    print(f\"Average number of Google searches per day for {type_data}: {avg_google_searches_per_day:.2f}\")\n",
    "    print(f\"Standard deviation of Google searches per day for {type_data}: {std_google_searches_per_day:.2f}\")\n",
    "\n",
    "    # Find the number of non-Google search site visits per day\n",
    "    daily_non_google_visits = google_df[~google_df[\"is_google_search\"]].groupby(google_df[\"datetime\"].dt.date).size()\n",
    "\n",
    "    # Get statistics\n",
    "    avg_non_google_sites_per_day = daily_non_google_visits.mean()\n",
    "    std_non_google_sites_per_day = daily_non_google_visits.std()\n",
    "\n",
    "    print(f\"Average number of non-Google search sites visited per day for {type_data}: {avg_non_google_sites_per_day:.2f}\")\n",
    "    print(f\"Standard deviation of non-Google search sites visited per day for {type_data}: {std_non_google_sites_per_day:.2f}\")\n",
    "\n",
    "    # Daily time series\n",
    "    daily = pd.DataFrame({\n",
    "        \"date\": daily_site_visits.index,\n",
    "        f\"total_sites_{type_data}\": daily_site_visits.values,\n",
    "        f\"google_searches_{type_data}\": daily_google_searches.reindex(daily_site_visits.index, fill_value=0).values,\n",
    "    })\n",
    "\n",
    "    # Summary stats\n",
    "    summary = {\n",
    "        \"type\": type_data,\n",
    "        \"total_searches\": search_count,\n",
    "        \"total_other\": other_count,\n",
    "        \"avg_sites_per_day\": avg_sites_per_day,\n",
    "        \"std_sites_per_day\": std_sites_per_day,\n",
    "        \"avg_searches_per_day\": avg_google_searches_per_day,\n",
    "        \"std_searches_per_day\": std_google_searches_per_day,\n",
    "        \"avg_non_searches_per_day\": avg_non_google_sites_per_day,\n",
    "        \"std_non_searches_per_day\": std_non_google_sites_per_day,\n",
    "    }\n",
    "\n",
    "# return it\n",
    "    return daily, pd.DataFrame([summary])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_daily, personal_summary = get_google_data(\"personal\")\n",
    "school_daily, school_summary = get_google_data(\"UVA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge by date!! So we can just have total sites visited\n",
    "merged_daily = pd.merge(personal_daily, school_daily, on=\"date\", how=\"outer\").fillna(0)\n",
    "merged_daily[\"date\"] = pd.to_datetime(merged_daily[\"date\"])\n",
    "\n",
    "# Plot side-by-side comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(merged_daily[\"date\"], merged_daily[\"total_sites_personal\"], label=\"Personal Browsing\")\n",
    "plt.plot(merged_daily[\"date\"], merged_daily[\"total_sites_UVA\"], label=\"UVA Browsing\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sites Visited\")\n",
    "plt.title(\"Personal vs. UVA Browsing Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "combined_summary = pd.concat([personal_summary, school_summary])\n",
    "print(combined_summary)\n",
    "\n",
    "# Total activity\n",
    "total_searches = combined_summary[\"total_searches\"].sum()\n",
    "total_other = combined_summary[\"total_other\"].sum()\n",
    "print(f\"Total Google Searches (combined): {total_searches}\")\n",
    "print(f\"Total Other Browsing (combined): {total_other}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_daily[\"total_sites_visited\"] = (\n",
    "    merged_daily[\"total_sites_personal\"] + merged_daily[\"total_sites_UVA\"]\n",
    ")\n",
    "\n",
    "google_browser_data = merged_daily\n",
    "google_browser_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just keep date and total sites visited\n",
    "use_google_browser_data = google_browser_data[[\"date\", \"total_sites_visited\"]]\n",
    "use_google_browser_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From now on, we use use_google_browser_data to access total browsing activity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitbit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sleep start/end times\n",
    "# Define the date range\n",
    "start_date = pd.to_datetime(\"2024-05-14\").date()\n",
    "end_date = pd.to_datetime(\"2025-04-15\").date()\n",
    "\n",
    "# Find all files that start with \"sleep\"\n",
    "sleep_files = glob.glob(\"./Takeout_personal/Fitbit/Global_Export_Data/sleep*.json\")\n",
    "\n",
    "print(\"Found sleep files:\", sleep_files)\n",
    "\n",
    "records = []\n",
    "\n",
    "for file in sleep_files:\n",
    "    print(f\"\\nProcessing file: {file}\") \n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            if not isinstance(data, list):\n",
    "                print(f\"Unexpected data format in {file}: {type(data)}. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            for session in data:\n",
    "                try:\n",
    "                    # Extract sleep session date\n",
    "                    date_str = session.get(\"dateOfSleep\", None)\n",
    "                    if not date_str:\n",
    "                        print(f\"Missing dateOfSleep in {file}, skipping entry.\")\n",
    "                        continue  # Skip if no dateOfSleep\n",
    "\n",
    "                    session_date = pd.to_datetime(date_str, errors=\"coerce\").date()\n",
    "                    \n",
    "                    print(f\"Extracted sleep date: {session_date}\")\n",
    "\n",
    "                    # Ensure it is within the desired date range\n",
    "                    if start_date <= session_date <= end_date:\n",
    "                        sleep_start = pd.to_datetime(session.get(\"startTime\", None), errors=\"coerce\")\n",
    "                        wake_time = pd.to_datetime(session.get(\"endTime\", None), errors=\"coerce\")\n",
    "\n",
    "                        if pd.notnull(sleep_start) and pd.notnull(wake_time):  \n",
    "                            records.append({\n",
    "                                \"date\": session_date,\n",
    "                                \"startTime\": sleep_start,\n",
    "                                \"endTime\": wake_time\n",
    "                            })\n",
    "                        else:\n",
    "                            print(f\"Invalid sleep times for {session_date}, skipping!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing session in {file}: {e}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error reading JSON file: {file}\")\n",
    "\n",
    "sleep_df = pd.DataFrame(records)\n",
    "\n",
    "if not sleep_df.empty and \"date\" in sleep_df.columns:\n",
    "    sleep_df = sleep_df.sort_values(\"date\").reset_index(drop=True)\n",
    "else:\n",
    "    print(\"No valid sleep records found in the date range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc sleep duration!\n",
    "sleep_df[\"startTime\"] = pd.to_datetime(sleep_df[\"startTime\"])\n",
    "sleep_df[\"endTime\"] = pd.to_datetime(sleep_df[\"endTime\"])\n",
    "sleep_df[\"sleep_duration\"] = sleep_df[\"endTime\"] - sleep_df[\"startTime\"]\n",
    "sleep_df[\"sleep_hours\"] = sleep_df[\"sleep_duration\"].dt.total_seconds() / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some stats\n",
    "sleep_df[\"sleep_hours\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sleep duration visualization...\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.plot(sleep_df[\"date\"], sleep_df[\"sleep_hours\"], linestyle='-', linewidth=2, color='steelblue', label=\"Sleep Duration\")\n",
    "plt.title(\"Daily Sleep Duration Over Time\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Hours of Sleep\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7-day rolling average of sleep hours\n",
    "sleep_df[\"rolling_7day_avg\"] = sleep_df[\"sleep_hours\"].rolling(window=7).mean()\n",
    "\n",
    "# Plot original + rolling average\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(sleep_df[\"date\"], sleep_df[\"sleep_hours\"], alpha=0.5, label=\"Daily Sleep\")\n",
    "plt.plot(sleep_df[\"date\"], sleep_df[\"rolling_7day_avg\"], color='red', linewidth=2, label=\"7-Day Rolling Avg\")\n",
    "plt.title(\"Sleep Duration with 7-Day Rolling Average\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Hours of Sleep\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sleep\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(sleep_df[\"sleep_hours\"], bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Sleep Durations\")\n",
    "plt.xlabel(\"Hours of Sleep\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "poor_sleep = sleep_df[sleep_df[\"sleep_hours\"] < 6]\n",
    "good_sleep = sleep_df[(sleep_df[\"sleep_hours\"] >= 6) & (sleep_df[\"sleep_hours\"] <= 9)]\n",
    "long_sleep = sleep_df[sleep_df[\"sleep_hours\"] > 9]\n",
    "\n",
    "print(f\"Number of short sleep nights (<6 hrs): {len(poor_sleep)}\")\n",
    "print(f\"Number of good sleep nights (6-9 hrs): {len(good_sleep)}\")\n",
    "print(f\"Number of long sleep nights (>9 hrs): {len(long_sleep)}\")\n",
    "\n",
    "sleep_df[\"date\"] = pd.to_datetime(sleep_df[\"date\"]) \n",
    "weekly_avg = sleep_df.set_index(\"date\")[\"sleep_hours\"].resample(\"W\").mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now add sleep score too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.read_csv(\"./Takeout_personal/Fitbit/Sleep_Score/sleep_score.csv\")\n",
    "\n",
    "# Convert timestamp to datetime and extract date\n",
    "score_df[\"date\"] = pd.to_datetime(score_df[\"timestamp\"]).dt.date\n",
    "\n",
    "# Keep only the date and score\n",
    "score_df = score_df[[\"date\", \"overall_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both to pandas datetime (no time part)\n",
    "sleep_df[\"date\"] = pd.to_datetime(sleep_df[\"date\"]).dt.normalize()\n",
    "score_df[\"date\"] = pd.to_datetime(score_df[\"date\"]).dt.normalize()\n",
    "sleep_df = pd.merge(sleep_df, score_df, on=\"date\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize!!\n",
    "\n",
    "\n",
    "# Rolling average\n",
    "sleep_df[\"rolling_7day_avg\"] = sleep_df[\"sleep_hours\"].rolling(window=7).mean()\n",
    "\n",
    "# Set up dual-axis plot\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Left Y-axis: Sleep hours\n",
    "ax1.plot(sleep_df[\"date\"], sleep_df[\"sleep_hours\"], color='lightblue', alpha=0.5, label=\"Daily Sleep\")\n",
    "ax1.plot(sleep_df[\"date\"], sleep_df[\"rolling_7day_avg\"], color='red', linewidth=2, label=\"7-Day Rolling Avg\")\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Sleep Duration (hrs)\", color='black')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Right Y-axis: Sleep score\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(sleep_df[\"date\"], sleep_df[\"overall_score\"], color='green', linestyle='--', label=\"Sleep Score\")\n",
    "ax2.set_ylabel(\"Sleep Score\", color='green')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "# Combine legends\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc=\"upper left\")\n",
    "\n",
    "# Title and layout\n",
    "plt.title(\"Sleep Duration and Sleep Score Over Time\")\n",
    "plt.xticks(rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix some naming to make sense for later\n",
    "use_sleep_data = sleep_df[[\"date\", \"startTime\", \"endTime\", \"sleep_hours\", \"overall_score\"]]\n",
    "use_sleep_data.rename(columns={\"startTime\": \"sleep_start_time\"}, inplace=True)\n",
    "use_sleep_data.rename(columns={\"endTime\": \"sleep_end_time\"}, inplace=True)\n",
    "use_sleep_data.rename(columns={\"overall_score\": \"sleep_score\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sleep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitbit Heart Rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range\n",
    "start_date = pd.to_datetime(\"2024-05-14\").date()\n",
    "end_date = pd.to_datetime(\"2025-04-15\").date()\n",
    "\n",
    "# All heart rate JSON files\n",
    "hr_files = glob.glob(\"./Takeout_personal/Fitbit/Global_Export_Data/heart_rate-*.json\")\n",
    "\n",
    "daily_averages = []\n",
    "\n",
    "# Loop through files\n",
    "for file_path in hr_files:\n",
    "    # Extract date from filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    date_str = filename.replace(\"heart_rate-\", \"\").replace(\".json\", \"\")\n",
    "    file_date = pd.to_datetime(date_str).date()\n",
    "\n",
    "    # Skip if out of date range\n",
    "    if not (start_date <= file_date <= end_date):\n",
    "        continue\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            bpm_values = []\n",
    "\n",
    "            for entry in data:\n",
    "                if isinstance(entry, dict) and \"value\" in entry:\n",
    "                    val = entry[\"value\"]\n",
    "                    if isinstance(val, dict) and \"bpm\" in val:\n",
    "                        bpm_values.append(val[\"bpm\"])\n",
    "\n",
    "            if bpm_values:\n",
    "                avg_bpm = sum(bpm_values) / len(bpm_values)\n",
    "                daily_averages.append({\"date\": file_date, \"avg_bpm\": avg_bpm})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {file_path} due to error: {e}\")\n",
    "\n",
    "# Final DataFrame\n",
    "heart_rate_daily_avg_df = pd.DataFrame(daily_averages)\n",
    "heart_rate_daily_avg_df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "print(heart_rate_daily_avg_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_daily_avg_df.rename(columns={\"avg_bpm\": \"avg_heart_rate\"}, inplace=True)\n",
    "heart_rate_daily_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize and stats\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(heart_rate_daily_avg_df[\"date\"], heart_rate_daily_avg_df[\"avg_heart_rate\"], color=\"salmon\", linewidth=2)\n",
    "plt.title(\"Daily Average Heart Rate Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg Heart Rate (BPM)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "heart_rate_daily_avg_df[\"rolling_avg\"] = heart_rate_daily_avg_df[\"avg_heart_rate\"].rolling(window=7).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(heart_rate_daily_avg_df[\"date\"], heart_rate_daily_avg_df[\"avg_heart_rate\"], color=\"lightcoral\", alpha=0.5, label=\"Daily Avg\")\n",
    "plt.plot(heart_rate_daily_avg_df[\"date\"], heart_rate_daily_avg_df[\"rolling_avg\"], color=\"darkred\", linewidth=2, label=\"7-Day Rolling Avg\")\n",
    "plt.title(\"Heart Rate with 7-Day Rolling Average\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Avg BPM\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(heart_rate_daily_avg_df[\"avg_heart_rate\"], bins=20, color=\"salmon\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Daily Average Heart Rate\")\n",
    "plt.xlabel(\"Avg BPM\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "max_hr = heart_rate_daily_avg_df[\"avg_heart_rate\"].max()\n",
    "min_hr = heart_rate_daily_avg_df[\"avg_heart_rate\"].min()\n",
    "avg_hr = heart_rate_daily_avg_df[\"avg_heart_rate\"].mean()\n",
    "std_hr = heart_rate_daily_avg_df[\"avg_heart_rate\"].std()\n",
    "\n",
    "print(f\"Max avg hr in a day: {max_hr}\")\n",
    "print(f\"Min avg hr in a day: {min_hr}\")\n",
    "print(f\"Average avg hr per day: {avg_hr:.2f}\")\n",
    "print(f\"Standard deviation: {std_hr:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitbit active level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date range\n",
    "start_date = pd.to_datetime(\"2024-05-14\").date()\n",
    "end_date = pd.to_datetime(\"2025-04-15\").date()\n",
    "\n",
    "# Mapping from prefix to new column name\n",
    "activity_types = {\n",
    "    \"very_active_minutes\": \"mins_very_active\",\n",
    "    \"moderately_active_minutes\": \"mins_moderately_active\",\n",
    "    \"lightly_active_minutes\": \"mins_lightly_active\",\n",
    "    \"sedentary_minutes\": \"mins_sedentary\"\n",
    "}\n",
    "\n",
    "# Collect daily rows for each activity type\n",
    "all_dfs = []\n",
    "\n",
    "for prefix, col_name in activity_types.items():\n",
    "    files = glob.glob(f\"./Takeout_personal/Fitbit/Global_Export_Data/{prefix}-*.json\")\n",
    "    rows = []\n",
    "\n",
    "    for file_path in files:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                for entry in data:\n",
    "                    if \"dateTime\" in entry and \"value\" in entry:\n",
    "                        dt = pd.to_datetime(entry[\"dateTime\"]).date()\n",
    "                        if start_date <= dt <= end_date:\n",
    "                            value = int(entry[\"value\"])\n",
    "                            rows.append({\"date\": dt, col_name: value})\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {file_path} due to error: {e}\")\n",
    "\n",
    "    # Convert this activity type to DataFrame\n",
    "    df = pd.DataFrame(rows).groupby(\"date\").sum().reset_index()\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Merge all activity type DataFrames on date\n",
    "from functools import reduce\n",
    "activity_df = reduce(lambda left, right: pd.merge(left, right, on=\"date\", how=\"outer\"), all_dfs)\n",
    "\n",
    "# Fill missing with 0 and sort\n",
    "activity_df.fillna(0, inplace=True)\n",
    "activity_df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize !!\n",
    "# Make sure dates are sorted and clean\n",
    "activity_df = activity_df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Create x positions and labels\n",
    "x = activity_df.index\n",
    "labels = activity_df[\"date\"].astype(str)  # safer if dt.strftime fails\n",
    "\n",
    "# Build stacked bar chart\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "plt.bar(x, activity_df[\"mins_sedentary\"], label=\"Sedentary\", color=\"#8c8c8c\")\n",
    "plt.bar(x, activity_df[\"mins_lightly_active\"],\n",
    "        bottom=activity_df[\"mins_sedentary\"], label=\"Lightly Active\", color=\"#a1d99b\")\n",
    "plt.bar(x, activity_df[\"mins_moderately_active\"],\n",
    "        bottom=activity_df[\"mins_sedentary\"] + activity_df[\"mins_lightly_active\"],\n",
    "        label=\"Moderately Active\", color=\"#fc8d62\")\n",
    "plt.bar(x, activity_df[\"mins_very_active\"],\n",
    "        bottom=activity_df[\"mins_sedentary\"] + activity_df[\"mins_lightly_active\"] + activity_df[\"mins_moderately_active\"],\n",
    "        label=\"Very Active\", color=\"#1f78b4\")\n",
    "\n",
    "# X-ticks every N days (optional, prevents overcrowding)\n",
    "tick_step = max(len(x) // 30, 1)  # Show ~30 labels max\n",
    "plt.xticks(ticks=x[::tick_step], labels=labels[::tick_step], rotation=90)\n",
    "\n",
    "# Set y-axis limit slightly above the tallest stacked bar\n",
    "max_total = (activity_df[[\"mins_sedentary\", \"mins_lightly_active\", \"mins_moderately_active\", \"mins_very_active\"]]\n",
    "             .sum(axis=1).max())\n",
    "\n",
    "plt.ylim(0, max_total * 1.05)  # 5% headroom\n",
    "\n",
    "# Axis labels and grid\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Minutes\")\n",
    "plt.title(\"Daily Activity Breakdown\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff types of visualization\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for col, color in zip(\n",
    "    [\"mins_very_active\", \"mins_moderately_active\", \"mins_lightly_active\", \"mins_sedentary\"],\n",
    "    [\"#1f78b4\", \"#fc8d62\", \"#a1d99b\", \"#8c8c8c\"]\n",
    "):\n",
    "    plt.plot(activity_df[\"date\"], activity_df[col], label=col.replace(\"mins_\", \"\").replace(\"_\", \" \").title(), linewidth=2, alpha=0.8, color=color)\n",
    "\n",
    "plt.title(\"Activity Level Trends Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Minutes\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df[\"active_total\"] = (\n",
    "    activity_df[\"mins_very_active\"] + activity_df[\"mins_moderately_active\"] + activity_df[\"mins_lightly_active\"]\n",
    ")\n",
    "activity_df[\"sedentary_total\"] = activity_df[\"mins_sedentary\"]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(activity_df[\"date\"], activity_df[\"active_total\"], label=\"Total Active\", color=\"green\", linewidth=2)\n",
    "plt.plot(activity_df[\"date\"], activity_df[\"sedentary_total\"], label=\"Sedentary\", color=\"gray\", linewidth=2)\n",
    "plt.title(\"Total Active vs Sedentary Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Minutes\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df[[\"mins_very_active\", \"mins_moderately_active\", \"mins_lightly_active\", \"mins_sedentary\"]].plot(\n",
    "    kind=\"box\", figsize=(10, 5), title=\"Distribution of Daily Activity Minutes\", grid=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df[\"mins_very_active\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df[\"mins_moderately_active\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df[\"mins_lightly_active\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df[\"mins_sedentary\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEPS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range\n",
    "start_date = pd.to_datetime(\"2024-05-14\").date()\n",
    "end_date = pd.to_datetime(\"2025-04-15\").date()\n",
    "\n",
    "# Find all relevant files\n",
    "step_files = glob.glob(\"./Takeout_personal/Fitbit/Physical_Activity_GoogleData/steps_*.csv\")\n",
    "\n",
    "daily_steps = []\n",
    "\n",
    "for file in step_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Parse timestamp and extract date\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "    df[\"date\"] = df[\"timestamp\"].dt.date\n",
    "\n",
    "    # Filter by date range\n",
    "    df = df[(df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)]\n",
    "\n",
    "    # Group and sum steps per day\n",
    "    daily_totals = df.groupby(\"date\")[\"steps\"].sum().reset_index()\n",
    "\n",
    "    daily_steps.append(daily_totals)\n",
    "\n",
    "# Combine all files' data\n",
    "steps_df = pd.concat(daily_steps).groupby(\"date\").sum().reset_index()\n",
    "\n",
    "steps_df.rename(columns={\"steps\": \"total_steps\"}, inplace=True)\n",
    "steps_df.sort_values(\"date\", inplace=True)\n",
    "steps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize steps\n",
    "\n",
    "# Compute 7-day rolling average\n",
    "steps_df[\"rolling_avg\"] = steps_df[\"total_steps\"].rolling(window=7).mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(steps_df[\"date\"], steps_df[\"total_steps\"], color=\"steelblue\", alpha=0.4, label=\"Daily Steps\")\n",
    "plt.plot(steps_df[\"date\"], steps_df[\"rolling_avg\"], color=\"navy\", linewidth=2, label=\"7-Day Rolling Avg\")\n",
    "plt.title(\"Daily Step Count with 7-Day Rolling Average\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = steps_df[\"total_steps\"].max()\n",
    "min_steps = steps_df[\"total_steps\"].min()\n",
    "avg_steps = steps_df[\"total_steps\"].mean()\n",
    "std_steps = steps_df[\"total_steps\"].std()\n",
    "\n",
    "print(f\"Max steps in a day: {max_steps}\")\n",
    "print(f\"Min steps in a day: {min_steps}\")\n",
    "print(f\"Average steps per day: {avg_steps:.2f}\")\n",
    "print(f\"Standard deviation: {std_steps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strava!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strava_df = pd.read_csv(\"./strava/activities.csv\")\n",
    "\n",
    "# Select relevant columns\n",
    "strava_clean = strava_df[[\"Activity Date\", \"Activity Type\", \"Distance\"]].copy()\n",
    "\n",
    "# Convert to datetime and filter date range\n",
    "strava_clean[\"Activity Date\"] = pd.to_datetime(strava_clean[\"Activity Date\"]).dt.date\n",
    "start_date = pd.to_datetime(\"2024-05-14\").date()\n",
    "end_date = pd.to_datetime(\"2025-04-15\").date()\n",
    "strava_clean = strava_clean[\n",
    "    (strava_clean[\"Activity Date\"] >= start_date) & \n",
    "    (strava_clean[\"Activity Date\"] <= end_date)\n",
    "]\n",
    "\n",
    "# Convert times/distances to numeric\n",
    "# strava_clean[\"Elapsed Time\"] = pd.to_numeric(strava_clean[\"Elapsed Time\"], errors=\"coerce\")\n",
    "strava_clean[\"Distance\"] = pd.to_numeric(strava_clean[\"Distance\"], errors=\"coerce\")\n",
    "\n",
    "# Drop incomplete rows\n",
    "strava_clean.dropna(subset=[\"Distance\"], inplace=True)\n",
    "\n",
    "# Sort by date (optional)\n",
    "strava_clean.sort_values(\"Activity Date\", inplace=True)\n",
    "\n",
    "strava_clean.rename(columns={\"Activity Date\": \"date\"}, inplace=True)\n",
    "strava_clean.rename(columns={\"Activity Type\": \"strava_activity_type\"}, inplace=True)\n",
    "# strava_clean.rename(columns={\"Elapsed Time\": \"strava_activity_time(mins)\"}, inplace=True)\n",
    "strava_clean.rename(columns={\"Distance\": \"strava_activity_distance(km)\"}, inplace=True)\n",
    "\n",
    "strava_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vis!!\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(data=strava_clean, x=\"date\", y=\"strava_activity_distance(km)\", hue=\"strava_activity_type\")\n",
    "plt.title(\"Distance Over Time by Activity Type\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Distance (km)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strava_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime format\n",
    "strava_clean[\"date\"] = pd.to_datetime(strava_clean[\"date\"])\n",
    "\n",
    "# Group by month and count number of activities\n",
    "monthly_counts = strava_clean.groupby(pd.Grouper(key=\"date\", freq=\"M\")).size()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "monthly_counts.plot(kind=\"bar\", color=\"skyblue\")\n",
    "plt.title(\"Total Number of Strava Activities per Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Activities\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:,.0f}\"))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=strava_clean, x=\"strava_activity_type\", y=\"strava_activity_distance(km)\", palette=\"Set2\")\n",
    "plt.title(\"Distribution of Distances by Activity Type\")\n",
    "plt.ylabel(\"Distance (km)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of the weeeek\n",
    "strava_clean[\"day_of_week\"] = pd.to_datetime(strava_clean[\"date\"]).dt.day_name()\n",
    "dow_counts = strava_clean.groupby([\"day_of_week\", \"strava_activity_type\"]).size().unstack().fillna(0)\n",
    "\n",
    "ordered_days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "dow_counts = dow_counts.reindex(ordered_days)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(dow_counts, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Strava Activities by Day of Week and Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv\n",
    "linkedin_df = pd.read_csv(\"./Linkedin/Connections.csv\")\n",
    "\n",
    "# Keep only the relevant columns\n",
    "linkedin_clean = linkedin_df[[\"Connected On\", \"Position\", \"Company\"]].copy()\n",
    "\n",
    "# Convert 'Connected On' to datetime\n",
    "linkedin_clean[\"Connected On\"] = pd.to_datetime(linkedin_clean[\"Connected On\"], errors=\"coerce\")\n",
    "\n",
    "# Filter for relevant date range\n",
    "start_date = pd.to_datetime(\"2024-05-14\")\n",
    "end_date = pd.to_datetime(\"2025-04-15\")\n",
    "linkedin_clean = linkedin_clean[\n",
    "    (linkedin_clean[\"Connected On\"] >= start_date) & (linkedin_clean[\"Connected On\"] <= end_date)\n",
    "]\n",
    "\n",
    "# Sort and rename columns\n",
    "linkedin_clean.sort_values(\"Connected On\", inplace=True)\n",
    "\n",
    "\n",
    "linkedin_clean.rename(columns={\"Connected On\": \"date\"}, inplace=True)\n",
    "linkedin_clean.rename(columns={\"Position\": \"linkedin_connection_position\"}, inplace=True)\n",
    "linkedin_clean.rename(columns={\"Company\": \"linkedin_connection_company\"}, inplace=True)\n",
    "\n",
    "linkedin_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and count by month\n",
    "monthly_connections = linkedin_clean.groupby(pd.Grouper(key=\"date\", freq=\"M\")).size()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = monthly_connections.plot(kind=\"bar\", color=\"steelblue\")\n",
    "plt.title(\"LinkedIn Connections per Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Connections\")\n",
    "\n",
    "month_labels = [d.strftime(\"%b\") for d in monthly_connections.index]\n",
    "plt.xticks(ticks=range(len(month_labels)), labels=month_labels, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_clean[\"linkedin_connection_company\"].value_counts().head(5).plot(kind=\"barh\", figsize=(8, 5), title=\"Top 5 Companies I Connected With\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_clean[\"linkedin_connection_position\"].value_counts().head(5).plot(kind=\"barh\", figsize=(8, 5), title=\"Top 5 Connection Titles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate\n",
    "linkedin_summary = (\n",
    "    linkedin_clean.groupby(\"date\")\n",
    "    .agg({\n",
    "        \"linkedin_connection_position\": lambda x: \"; \".join(x.dropna().astype(str).unique()),\n",
    "        \"linkedin_connection_company\": lambda x: \"; \".join(x.dropna().astype(str).unique()),\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "# Also add connection count per day\n",
    "linkedin_summary[\"linkedin_connection_count\"] = (\n",
    "    linkedin_clean.groupby(\"date\").size()\n",
    ")\n",
    "\n",
    "# Reset index to keep 'date' as a column\n",
    "linkedin_summary.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add message count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df = pd.read_csv(\"./Linkedin/messages.csv\")\n",
    "\n",
    "# Parse date column\n",
    "messages_df[\"DATE\"] = pd.to_datetime(messages_df[\"DATE\"], errors=\"coerce\")\n",
    "messages_df.dropna(subset=[\"DATE\"], inplace=True)\n",
    "\n",
    "# Extract just the date\n",
    "messages_df[\"date\"] = messages_df[\"DATE\"].dt.date\n",
    "\n",
    "# Filter to relevant date range\n",
    "start_date = pd.to_datetime(\"2024-05-14\").date()\n",
    "end_date = pd.to_datetime(\"2025-04-15\").date()\n",
    "messages_df = messages_df[(messages_df[\"date\"] >= start_date) & (messages_df[\"date\"] <= end_date)]\n",
    "\n",
    "# Count messages per day\n",
    "message_counts = messages_df.groupby(\"date\").size().reset_index(name=\"linkedin_message_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "# Make sure linkedin_summary has date in the same format\n",
    "linkedin_summary[\"date\"] = pd.to_datetime(linkedin_summary[\"date\"]).dt.date\n",
    "\n",
    "# Merge\n",
    "linkedin_summary = linkedin_summary.merge(message_counts, on=\"date\", how=\"left\")\n",
    "\n",
    "# Fill missing days with 0 messages\n",
    "linkedin_summary[\"linkedin_message_count\"] = linkedin_summary[\"linkedin_message_count\"].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize combo \n",
    "# Ensure 'date' is datetime type\n",
    "linkedin_summary[\"date\"] = pd.to_datetime(linkedin_summary[\"date\"])\n",
    "\n",
    "# Sort by date for plotting\n",
    "linkedin_summary.sort_values(\"date\", inplace=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.plot(linkedin_summary[\"date\"], linkedin_summary[\"linkedin_connection_count\"], label=\"Connections\", marker=\"o\", color=\"steelblue\")\n",
    "plt.plot(linkedin_summary[\"date\"], linkedin_summary[\"linkedin_message_count\"], label=\"Messages\", marker=\"s\", color=\"darkorange\")\n",
    "\n",
    "plt.title(\"LinkedIn Connections and Messages Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(\"2024-05-14\")\n",
    "end_date   = pd.to_datetime(\"2025-04-15\")\n",
    "\n",
    "# Generate a date range covering every day in [start_date..end_date].\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Count how many messages were sent each day\n",
    "message_counts = defaultdict(int)\n",
    "\n",
    "inbox_path = \"instagram/your_instagram_activity/messages/inbox\"\n",
    "for convo_folder in os.listdir(inbox_path):\n",
    "    convo_path = os.path.join(inbox_path, convo_folder)\n",
    "    if os.path.isdir(convo_path):\n",
    "        for filename in os.listdir(convo_path):\n",
    "            if filename.endswith(\".json\"):\n",
    "                with open(os.path.join(convo_path, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                    try:\n",
    "                        data = json.load(f)\n",
    "                        for msg in data.get(\"messages\", []):\n",
    "                            # Match sender name as needed here \n",
    "                            if msg.get(\"sender_name\") == \"Maria\":\n",
    "                                ts_ms = msg.get(\"timestamp_ms\")\n",
    "                                if ts_ms:\n",
    "                                    # Convert ms -> seconds to create a proper datetime\n",
    "                                    dt = datetime.fromtimestamp(ts_ms / 1000.0)\n",
    "                                    # Only count if within  date window\n",
    "                                    if start_date <= dt <= end_date:\n",
    "                                        # Use a YYYY-MM-DD string or a normalized datetime\n",
    "                                        day = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "                                        message_counts[day] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in {filename}: {e}\")\n",
    "\n",
    "# Convert those counts into a DataFrame\n",
    "messages_df = pd.DataFrame({\"date\": all_dates})\n",
    "# Map each date in the range to the count, default 0\n",
    "messages_df[\"instagram_messages_sent\"] = messages_df[\"date\"].map(lambda d: message_counts.get(d, 0))\n",
    "\n",
    "messages_df[\"instagram_messages_sent\"] = messages_df[\"instagram_messages_sent\"].astype(int)\n",
    "\n",
    "print(messages_df.head(5))\n",
    "print(messages_df.tail(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liked posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime(\"2024-05-14\")\n",
    "end_date   = pd.to_datetime(\"2025-04-15\")\n",
    "\n",
    "# Full daily range again\n",
    "full_dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "\n",
    "# Load liked posts\n",
    "with open(\"./instagram/your_instagram_activity/likes/liked_posts.json\", \"r\") as f:\n",
    "    post_data = json.load(f)\n",
    "\n",
    "post_counts = {}\n",
    "\n",
    "# Loop over each post-like record\n",
    "for item in post_data.get(\"likes_media_likes\", []):\n",
    "    for entry in item.get(\"string_list_data\", []):\n",
    "        ts = entry.get(\"timestamp\")\n",
    "        if ts:\n",
    "            # If timestamps are in ms, convert them:\n",
    "            # had issues\n",
    "            if ts > 1e12:\n",
    "                ts = ts // 1000\n",
    "\n",
    "            dt = datetime.fromtimestamp(ts)\n",
    "            if start_date <= dt <= end_date:\n",
    "                # Normalize to midnight for consistent day matching\n",
    "                dt_midnight = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "                post_counts[dt_midnight] = post_counts.get(dt_midnight, 0) + 1\n",
    "\n",
    "# Build DataFrame from these counts\n",
    "liked_posts_df = pd.DataFrame({\"date\": list(post_counts.keys()),\n",
    "                               \"instagram_liked_posts_count\": list(post_counts.values())})\n",
    "\n",
    "# Make sure 'date' is a full Timestamp (midnight)\n",
    "liked_posts_df[\"date\"] = pd.to_datetime(liked_posts_df[\"date\"])\n",
    "\n",
    "# Reindex so *all* dates in the range appear, missing ones filled with 0\n",
    "liked_posts_df = (\n",
    "    liked_posts_df\n",
    "    .set_index(\"date\")\n",
    "    .reindex(full_dates, fill_value=0)\n",
    "    .rename_axis(\"date\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "liked_posts_df[\"instagram_liked_posts_count\"] = liked_posts_df[\"instagram_liked_posts_count\"].astype(int)\n",
    "\n",
    "print(liked_posts_df.head(5))\n",
    "print(liked_posts_df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_df = pd.merge(messages_df, liked_posts_df, on=\"date\", how=\"outer\")\n",
    "\n",
    "# Fill any NaNs (in case one side had a day the other did not) with 0\n",
    "instagram_df[[\"instagram_messages_sent\",\"instagram_liked_posts_count\"]] = instagram_df[[\"instagram_messages_sent\",\"instagram_liked_posts_count\"]].fillna(0).astype(int)\n",
    "\n",
    "instagram_df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "instagram_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_df[\"instagram_messages_sent\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_df[\"instagram_liked_posts_count\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIS!\n",
    "# Calculate rolling averages\n",
    "rolling = instagram_df.copy()\n",
    "rolling[\"messages_rolling\"] = rolling[\"instagram_messages_sent\"].rolling(window=7).mean()\n",
    "rolling[\"likes_rolling\"] = rolling[\"instagram_liked_posts_count\"].rolling(window=7).mean()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Light base lines\n",
    "plt.plot(instagram_df[\"date\"], instagram_df[\"instagram_messages_sent\"], label=\"Messages (Daily)\", color=\"skyblue\", alpha=0.3)\n",
    "plt.plot(instagram_df[\"date\"], instagram_df[\"instagram_liked_posts_count\"], label=\"Posts Liked (Daily)\", color=\"orange\", alpha=0.3)\n",
    "\n",
    "# Bold rolling averages\n",
    "plt.plot(rolling[\"date\"], rolling[\"messages_rolling\"], label=\"Messages (7-Day Avg)\", color=\"skyblue\", linewidth=2.5)\n",
    "plt.plot(rolling[\"date\"], rolling[\"likes_rolling\"], label=\"Posts Liked (7-Day Avg)\", color=\"orange\", linewidth=2.5)\n",
    "\n",
    "plt.title(\"Daily Instagram Activity with 7-Day Rolling Averages\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = instagram_df.copy()\n",
    "weekly[\"week\"] = weekly[\"date\"].dt.to_period(\"W\").apply(lambda r: r.start_time)\n",
    "weekly_totals = weekly.groupby(\"week\")[[\"instagram_messages_sent\", \"instagram_liked_posts_count\"]].sum()\n",
    "\n",
    "weekly_totals.plot(kind=\"bar\", figsize=(15, 5), stacked=True, color=[\"skyblue\", \"orange\"])\n",
    "plt.title(\"Weekly Instagram Activity\")\n",
    "plt.xlabel(\"Week\")\n",
    "plt.ylabel(\"Total Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = instagram_df.copy()\n",
    "dow[\"day\"] = dow[\"date\"].dt.day_name()\n",
    "\n",
    "dow_summary = dow.groupby(\"day\")[[\"instagram_messages_sent\", \"instagram_liked_posts_count\"]].mean().reindex([\n",
    "    \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"\n",
    "])\n",
    "\n",
    "dow_summary.plot(kind=\"bar\", figsize=(10, 4), color=[\"skyblue\", \"orange\"])\n",
    "plt.title(\"Average Instagram Activity by Day of Week\")\n",
    "plt.ylabel(\"Average Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(merged_df[\"instagram_messages_sent\"], merged_df[\"instagram_liked_posts_count\"], alpha=0.5, color=\"purple\")\n",
    "plt.title(\"Relationship Between Messages Sent & Posts Liked\")\n",
    "plt.xlabel(\"Messages Sent\")\n",
    "plt.ylabel(\"Posts Liked\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, putting them all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all df together for all data!\n",
    "# First, print the head of each DataFrame to check\n",
    "print(\"use_google_browser_data:\")\n",
    "print(use_google_browser_data.head(), \"\\n\")\n",
    "\n",
    "print(\"use_sleep_data:\")\n",
    "print(use_sleep_data.head(), \"\\n\")\n",
    "\n",
    "print(\"heart_rate_daily_avg_df:\")\n",
    "print(heart_rate_daily_avg_df.head(), \"\\n\")\n",
    "\n",
    "print(\"activity_df:\")\n",
    "print(activity_df.head(), \"\\n\")\n",
    "\n",
    "print(\"steps_df:\")\n",
    "print(steps_df.head(), \"\\n\")\n",
    "\n",
    "print(\"strava_clean:\")\n",
    "print(strava_clean.head(), \"\\n\")\n",
    "\n",
    "print(\"linkedin_summary:\")\n",
    "print(linkedin_summary.head(), \"\\n\")\n",
    "\n",
    "print(\"Instagram_df:\")\n",
    "print(instagram_df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dataframes\n",
    "dfs = [\n",
    "    use_google_browser_data,\n",
    "    use_sleep_data,\n",
    "    heart_rate_daily_avg_df,\n",
    "    activity_df,\n",
    "    steps_df,\n",
    "    strava_clean,\n",
    "    linkedin_summary,\n",
    "    instagram_df\n",
    "]\n",
    "\n",
    "original_dtypes = {}\n",
    "\n",
    "def rename_and_collect_dtypes(df, index):\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.normalize()\n",
    "    \n",
    "    # Rename only if column doesn't already have suffix\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        if col == \"date\":\n",
    "            new_cols.append(\"date\")\n",
    "        elif f\"_df{index}\" not in col:  # prevent repeated renaming\n",
    "            new_cols.append(f\"{col}_df{index}\")\n",
    "        else:\n",
    "            new_cols.append(col)\n",
    "    df.columns = new_cols\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != \"date\":\n",
    "            original_dtypes[col] = df[col].dtype\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean and rename\n",
    "dfs = [rename_and_collect_dtypes(df, i) for i, df in enumerate(dfs)]\n",
    "\n",
    "# Merge all on 'date'\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on=\"date\", how=\"outer\"), dfs)\n",
    "\n",
    "# Restore dtypes\n",
    "for col in merged_df.columns:\n",
    "    if col == \"date\":\n",
    "        continue\n",
    "\n",
    "    orig_dtype = original_dtypes.get(col, None)\n",
    "    if orig_dtype is None:\n",
    "        continue\n",
    "\n",
    "    if pd.api.types.is_integer_dtype(orig_dtype):\n",
    "        merged_df[col] = merged_df[col].astype(\"Int64\")\n",
    "    elif pd.api.types.is_float_dtype(orig_dtype):\n",
    "        merged_df[col] = merged_df[col].astype(float)\n",
    "    elif pd.api.types.is_object_dtype(orig_dtype) or pd.api.types.is_string_dtype(orig_dtype):\n",
    "        merged_df[col] = merged_df[col].astype(object)\n",
    "\n",
    "# Sort by date\n",
    "merged_df.sort_values(\"date\", inplace=True)\n",
    "\n",
    "print(merged_df.info())\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to manually edit the column names after saving...\n",
    "merged_df\n",
    "merged_df.to_csv(\"merged_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_data.csv\", parse_dates=[\"date\"])\n",
    "df\n",
    "\n",
    "# Want total social media interaction...\n",
    "df[\"instagram_total_interactions\"] = df[\"instagram_messages_sent\"] + df[\"instagram_liked_posts_count\"]\n",
    "\n",
    "df = df.drop(columns=[\"rolling_avg\"])\n",
    "\n",
    "df.to_csv(\"merged_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "merged_data = pd.read_csv(\"merged_data.csv\")\n",
    "\n",
    "# Get the number of rows\n",
    "num_rows = merged_data.shape[0]\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML-IA-class)",
   "language": "python",
   "name": "ml-ia-class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
