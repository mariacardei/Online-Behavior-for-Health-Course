{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "pio.renderers.default = \"notebook\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project analysis: first statistical correlations, then with life events, then ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_data.csv\", parse_dates=[\"date\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore correlations within my own behavior\n",
    "# Pearson correlation coefficient bw every pair of numeric columns in df\n",
    "correlations = df.corr(numeric_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix of Behavior Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate correlation matrix with numeric columns\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Unstack the matrix to long format\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "\n",
    "# Drop self-correlations\n",
    "corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]\n",
    "\n",
    "# Drop duplicate pairs (e.g., keep A-B, drop B-A)\n",
    "corr_pairs = corr_pairs.sort_values(key=lambda x: np.abs(x), ascending=False).drop_duplicates()\n",
    "\n",
    "# Show top 20 relationships\n",
    "top_n = 20\n",
    "print(corr_pairs.head(top_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually make list to then remove for easier analysis...\n",
    "expected_links = [\n",
    "    (\"mins_sedentary\", \"sedentary_total\"),\n",
    "    (\"instagram_total_interactions\", \"instagram_messages_sent\"),\n",
    "    (\"active_total\", \"mins_lightly_active\"),\n",
    "    (\"active_total\", \"sedentary_total\"),\n",
    "    (\"mins_sedentary\", \"active_total\"),\n",
    "    (\"total_steps\", \"active_total\"),\n",
    "    (\"mins_lightly_active\", \"sedentary_total\"),\n",
    "    (\"avg_heart_rate\", \"active_total\"),\n",
    "    (\"total_steps\", \"mins_lightly_active\"),\n",
    "    (\"mins_very_active\", \"avg_heart_rate\"),\n",
    "    (\"mins_moderately_active\", \"active_total\"),\n",
    "    (\"mins_sedentary\", \"avg_heart_rate\"),\n",
    "    (\"mins_very_active\", \"mins_moderately_active\"),\n",
    "    (\"total_steps\", \"mins_very_active\"),\n",
    "    (\"total_steps\", \"avg_heart_rate\"),\n",
    "    (\"mins_lightly_active\", \"avg_heart_rate\"),\n",
    "    (\"total_steps\", \"mins_moderately_active\"),\n",
    "    (\"mins_sedentary\", \"total_steps\"),\n",
    "    (\"rolling_avg\", \"avg_heart_rate\"),\n",
    "    (\"sleep_score\", \"sleep_hours\"),\n",
    "]\n",
    "\n",
    "# Compute correlations\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "corr_pairs = corr_pairs[corr_pairs.index.get_level_values(0) != corr_pairs.index.get_level_values(1)]\n",
    "corr_pairs = corr_pairs.sort_values(key=lambda x: np.abs(x), ascending=False).drop_duplicates()\n",
    "\n",
    "# Filter out expected links\n",
    "expected_set = set(tuple(sorted(pair)) for pair in expected_links)\n",
    "filtered_pairs = [pair for pair in corr_pairs.index if tuple(sorted(pair)) not in expected_set]\n",
    "filtered_corrs = corr_pairs.loc[filtered_pairs]\n",
    "\n",
    "print(filtered_corrs.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCC and P value!\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each pair of numeric columns\n",
    "cols = numeric_df.columns\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        col1 = cols[i]\n",
    "        col2 = cols[j]\n",
    "        # Drop NaNs for both columns before computing\n",
    "        valid = numeric_df[[col1, col2]].dropna()\n",
    "        if len(valid) > 1:\n",
    "            corr, pval = pearsonr(valid[col1], valid[col2])\n",
    "            results.append({\n",
    "                \"var1\": col1,\n",
    "                \"var2\": col2,\n",
    "                \"correlation\": corr,\n",
    "                \"p_value\": pval,\n",
    "                \"abs_correlation\": abs(corr)\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "correlation_df = pd.DataFrame(results)\n",
    "\n",
    "# Filter for statistically significant results\n",
    "significant_corrs = correlation_df[correlation_df[\"p_value\"] < 0.05]\n",
    "\n",
    "# Sort by absolute correlation strength\n",
    "significant_corrs = significant_corrs.sort_values(by=\"abs_correlation\", ascending=False)\n",
    "\n",
    "# Display results\n",
    "significant_corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop VERY HIGHLY similar columns to reduce coliearity, redundancy, etc....\n",
    "df = df.drop(columns=[\"sedentary_total\", \"instagram_total_interactions\", \"active_total\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_df = df.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each pair of numeric columns\n",
    "cols = numeric_df.columns\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i + 1, len(cols)):\n",
    "        col1 = cols[i]\n",
    "        col2 = cols[j]\n",
    "        # Drop NaNs for both columns before computing\n",
    "        valid = numeric_df[[col1, col2]].dropna()\n",
    "        if len(valid) > 1:\n",
    "            corr, pval = pearsonr(valid[col1], valid[col2])\n",
    "            results.append({\n",
    "                \"var1\": col1,\n",
    "                \"var2\": col2,\n",
    "                \"correlation\": corr,\n",
    "                \"p_value\": pval,\n",
    "                \"abs_correlation\": abs(corr)\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "correlation_df = pd.DataFrame(results)\n",
    "\n",
    "# Filter for statistically significant results\n",
    "significant_corrs = correlation_df[correlation_df[\"p_value\"] < 0.05]\n",
    "\n",
    "# Sort by absolute correlation strength\n",
    "significant_corrs = significant_corrs.sort_values(by=\"abs_correlation\", ascending=False)\n",
    "\n",
    "# Display results\n",
    "significant_corrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "plot_df = df[[\"avg_heart_rate\", \"mins_very_active\"]].dropna()\n",
    "\n",
    "# Compute correlation and p-value\n",
    "corr, pval = pearsonr(plot_df[\"mins_very_active\"], plot_df[\"avg_heart_rate\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(data=plot_df, x=\"mins_very_active\", y=\"avg_heart_rate\", scatter_kws={'alpha':0.6})\n",
    "plt.title(\"Relationship Between Activity and Average Heart Rate\")\n",
    "plt.xlabel(\"Total Active Minutes\")\n",
    "plt.ylabel(\"Average Heart Rate\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Add text box with correlation and p-value\n",
    "plt.text(\n",
    "    0.05, 0.95,\n",
    "    f\"r = {corr:.2f}\\np = {pval:.3g}\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=12,\n",
    "    verticalalignment='top',\n",
    "    bbox=dict(boxstyle='round', facecolor='white', alpha=0.6)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a cool 3D visualization!\n",
    "# Drop missing values\n",
    "plot_df = df[[\"avg_heart_rate\", \"mins_very_active\", \"total_steps\"]].dropna()\n",
    "\n",
    "# Create interactive 3D scatter\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=plot_df[\"mins_very_active\"],\n",
    "    y=plot_df[\"total_steps\"],\n",
    "    z=plot_df[\"avg_heart_rate\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=4,\n",
    "        color=plot_df[\"avg_heart_rate\"],\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.7,\n",
    "        colorbar=dict(title='Avg Heart Rate')\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Total Very Active Minutes',\n",
    "        yaxis_title='Total Steps',\n",
    "        zaxis_title='Average Heart Rate',\n",
    "        zaxis=dict(range=[50, 95])  # manually increase z-axis space\n",
    "    ),\n",
    "    title=\"Interactive 3D: Heart Rate vs Activity vs Steps\",\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_html(\"cool_plot.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "plot_df = df[[\"total_sites_visited\", \"mins_lightly_active\"]].dropna()\n",
    "\n",
    "# Compute correlation and p-value\n",
    "corr, pval = pearsonr(plot_df[\"total_sites_visited\"], plot_df[\"mins_lightly_active\"])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.regplot(\n",
    "    data=plot_df,\n",
    "    x=\"total_sites_visited\",\n",
    "    y=\"mins_lightly_active\",\n",
    "    scatter_kws={'alpha': 0.6}\n",
    ")\n",
    "\n",
    "plt.title(\"Total Sites Visited vs Lightly Active Minutes\")\n",
    "plt.xlabel(\"Total Sites Visited\")\n",
    "plt.ylabel(\"Minutes Lightly Active\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Add correlation + p-value as annotation\n",
    "plt.text(\n",
    "    0.60, 0.95,\n",
    "    f\"r = {corr:.2f}\\np = {pval:.3g}\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=12,\n",
    "    verticalalignment='top',\n",
    "    bbox=dict(boxstyle='round', facecolor='white', alpha=0.6)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not look at more pairs of relationships: define the variable pairs want to plot\n",
    "pairs = [\n",
    "    (\"sleep_hours\", \"mins_sedentary\"),\n",
    "    (\"total_sites_visited\", \"instagram_liked_posts_count\"),\n",
    "    (\"total_sites_visited\", \"avg_heart_rate\"),\n",
    "    (\"mins_moderately_active\", \"instagram_messages_sent\"),\n",
    "    (\"sleep_score\", \"instagram_messages_sent\"),\n",
    "    (\"sleep_hours\", \"avg_heart_rate\"),\n",
    "]\n",
    "\n",
    "# Generate a plot for each pair\n",
    "for x_var, y_var in pairs:\n",
    "    # Drop missing values\n",
    "    plot_df = df[[x_var, y_var]].dropna()\n",
    "    \n",
    "    # Compute correlation and p-value\n",
    "    corr, pval = pearsonr(plot_df[x_var], plot_df[y_var])\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.regplot(data=plot_df, x=x_var, y=y_var, scatter_kws={'alpha': 0.6})\n",
    "    plt.title(f\"{x_var.replace('_', ' ').title()} vs {y_var.replace('_', ' ').title()}\")\n",
    "    plt.xlabel(x_var.replace(\"_\", \" \").title())\n",
    "    plt.ylabel(y_var.replace(\"_\", \" \").title())\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Annotate with correlation + p-value\n",
    "    plt.text(\n",
    "        0.05, 0.95,\n",
    "        f\"r = {corr:.2f}\\np = {pval:.3g}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=12,\n",
    "        verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.6)\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Timeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add events here! I removed mine for public possting\n",
    "life_events = [\n",
    "    {\"event\": \"fam visit\", \"event_type\": \"visit\", \"start\": \"2024-05-15\", \"end\": \"2024-05-19\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = life_events\n",
    "# Save to a JSON file\n",
    "with open(\"all_life_events.json\", \"w\") as f:\n",
    "    json.dump(all_events, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"events\"] = [[] for _ in range(len(df))]\n",
    "df[\"event_types\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "for e in all_events:\n",
    "    start = pd.to_datetime(e[\"start\"])\n",
    "    end = pd.to_datetime(e[\"end\"])\n",
    "    mask = (df[\"date\"] >= start) & (df[\"date\"] <= end)\n",
    "\n",
    "    df.loc[mask, \"events\"] = df.loc[mask, \"events\"].apply(lambda x: x + [e[\"event\"]])\n",
    "    df.loc[mask, \"event_types\"] = df.loc[mask, \"event_types\"].apply(lambda x: x + [e[\"event_type\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of each type of event\n",
    "df[df[\"event_types\"].apply(lambda x: \"interview\" in x)]\n",
    "from collections import Counter\n",
    "event_type_counts = Counter([et for sublist in df[\"event_types\"] for et in sublist])\n",
    "print(event_type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "df.to_csv(\"merged_data_with_events.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stat analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with no event_types\n",
    "df_exploded = df[df[\"event_types\"].map(len) > 0].explode(\"event_types\")\n",
    "\n",
    "# Get numeric columns\n",
    "numeric_cols = df_exploded.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Group by event type and compute means\n",
    "grouped_stats = df_exploded.groupby(\"event_types\")[numeric_cols].mean().T.sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_normalized = (grouped_stats - grouped_stats.mean(axis=1).values[:, None]) / grouped_stats.std(axis=1).values[:, None]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(grouped_normalized, cmap=\"coolwarm\", center=0, annot=False)\n",
    "plt.title(\"Average Numeric Feature Values by Event Type\")\n",
    "plt.xlabel(\"Event Type\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten all event types across all rows\n",
    "event_type_counts = Counter([etype for sublist in df[\"event_types\"] for etype in sublist])\n",
    "\n",
    "# Print sorted count\n",
    "event_type_counts = dict(sorted(event_type_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "for event_type, count in event_type_counts.items():\n",
    "    print(f\"{event_type}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyp: Different event types (like \"lab meeting\", \"deadline\", \"holiday\", etc.) significantly influence my behavior (activity, heart rate, screen time, social media use, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "import pandas as pd\n",
    "\n",
    "# kruskal-wallis test to see if feature is sigificantly affected by event type!\n",
    "\n",
    "# Explode event_types list\n",
    "df_exploded = df[df[\"event_types\"].map(len) > 0].explode(\"event_types\")\n",
    "\n",
    "# Get numeric columns\n",
    "numeric_cols = df_exploded.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Top event types to consider (avoid tiny groups)\n",
    "top_event_types = df_exploded[\"event_types\"].value_counts().head(10).index\n",
    "\n",
    "# Run Kruskal-Wallis and store results + per-event-type means\n",
    "results = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    groups = [df_exploded[df_exploded[\"event_types\"] == etype][col].dropna() for etype in top_event_types]\n",
    "    \n",
    "    if all(len(g) > 1 for g in groups):\n",
    "        stat, p = kruskal(*groups)\n",
    "\n",
    "        # Compute per-event-type means for this feature\n",
    "        means = {etype: df_exploded[df_exploded[\"event_types\"] == etype][col].mean() for etype in top_event_types}\n",
    "\n",
    "        results.append({\n",
    "            \"feature\": col,\n",
    "            \"statistic\": stat,\n",
    "            \"p_value\": p,\n",
    "            \"means_by_event_type\": means\n",
    "        })\n",
    "\n",
    "# Format results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by p-value\n",
    "results_df = results_df.sort_values(by=\"p_value\")\n",
    "\n",
    "# Display top rows\n",
    "for _, row in results_df.iterrows():\n",
    "    print(f\"\\n Feature: {row['feature']}\")\n",
    "    print(f\"p = {row['p_value']:.4f}\")\n",
    "    print(\"Event Type Means:\")\n",
    "    for etype, mean_val in row[\"means_by_event_type\"].items():\n",
    "        print(f\"     {etype}: {mean_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import itertools\n",
    "\n",
    "# Determine statistically significant differences of every feature for pairwise event comparison\n",
    "\n",
    "# Explode event_types so each row has one type\n",
    "df_exploded = df[df[\"event_types\"].map(len) > 0].explode(\"event_types\")\n",
    "\n",
    "# Get numeric columns\n",
    "numeric_cols = df_exploded.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Get most common event types\n",
    "top_event_types = df_exploded[\"event_types\"].value_counts().head(3).index.tolist()\n",
    "\n",
    "# Store results\n",
    "pairwise_results = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    for et1, et2 in itertools.combinations(top_event_types, 2):\n",
    "        group1 = df_exploded[df_exploded[\"event_types\"] == et1][col].dropna()\n",
    "        group2 = df_exploded[df_exploded[\"event_types\"] == et2][col].dropna()\n",
    "\n",
    "        if len(group1) > 1 and len(group2) > 1:\n",
    "            stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "            pairwise_results.append({\n",
    "                \"feature\": col,\n",
    "                \"event_type_1\": et1,\n",
    "                \"event_type_2\": et2,\n",
    "                \"p_value\": p,\n",
    "                \"mean_1\": group1.mean(),\n",
    "                \"mean_2\": group2.mean()\n",
    "            })\n",
    "\n",
    "# Format results\n",
    "pairwise_df = pd.DataFrame(pairwise_results)\n",
    "pairwise_df = pairwise_df.sort_values(\"p_value\")\n",
    "\n",
    "# Show top significant differences\n",
    "print(pairwise_df[pairwise_df[\"p_value\"] < 0.05])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "\n",
    "# Top features to visualize\n",
    "top_features = [\"sleep_score\", \"avg_heart_rate\", \"total_sites_visited\", \"instagram_messages_sent\"]\n",
    "\n",
    "# Choose a color palette for distinct event types\n",
    "palette = sns.color_palette(\"Set2\", n_colors=len(top_event_types))\n",
    "\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    ax = sns.violinplot(\n",
    "        data=df_plot,\n",
    "        x=\"event_types\",\n",
    "        y=feature,\n",
    "        inner=\"quartile\",        \n",
    "        scale=\"width\",           \n",
    "        linewidth=1.1,\n",
    "        palette=palette         \n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"{feature.replace('_', ' ').title()} by Event Type\", fontsize=14, weight=\"bold\")\n",
    "    ax.set_xlabel(\"Event Type\", fontsize=12)\n",
    "    ax.set_ylabel(feature.replace('_', ' ').title(), fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looking at interview days!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_interview_day\"] = df[\"event_types\"].apply(lambda x: \"interview\" in x).astype(int)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "features_to_test = [\"linkedin_connection_count\", \"linkedin_message_count\"]\n",
    "\n",
    "for col in features_to_test:\n",
    "    group_interview = df[df[\"is_interview_day\"] == 1][col].dropna()\n",
    "    group_non = df[df[\"is_interview_day\"] == 0][col].dropna()\n",
    "    \n",
    "    if len(group_interview) > 1 and len(group_non) > 1:\n",
    "        stat, p = mannwhitneyu(group_interview, group_non, alternative=\"two-sided\")\n",
    "        print(f\"{col}: p = {p:.4f}, mean (interview) = {group_interview.mean():.2f}, mean (non) = {group_non.mean():.2f}\")\n",
    "\n",
    "for col in features_to_test:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.violinplot(data=df, x=\"is_interview_day\", y=col, palette=\"Set2\", inner=\"quartile\")\n",
    "    plt.title(f\"{col.replace('_', ' ').title()} on Interview vs Non-Interview Days\")\n",
    "    plt.xticks([0, 1], [\"Non-Interview\", \"Interview\"])\n",
    "    plt.ylabel(col.replace('_', ' ').title())\n",
    "    plt.xlabel(\"Day Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "results = []\n",
    "\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    if col == \"is_interview_day\":\n",
    "        continue\n",
    "    group_interview = df[df[\"is_interview_day\"] == 1][col].dropna()\n",
    "    group_non = df[df[\"is_interview_day\"] == 0][col].dropna()\n",
    "    \n",
    "    if len(group_interview) > 1 and len(group_non) > 1:\n",
    "        stat, p = mannwhitneyu(group_interview, group_non)\n",
    "        results.append({\n",
    "            \"feature\": col,\n",
    "            \"p_value\": p,\n",
    "            \"mean_interview\": group_interview.mean(),\n",
    "            \"mean_non_interview\": group_non.mean()\n",
    "        })\n",
    "\n",
    "# View sorted results\n",
    "pd.DataFrame(results).sort_values(\"p_value\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.boxplot(data=df, x=\"is_interview_day\", y=\"linkedin_connection_count\", palette=\"Set2\")\n",
    "sns.swarmplot(data=df, x=\"is_interview_day\", y=\"linkedin_connection_count\", color=\".3\", alpha=0.6)\n",
    "plt.title(\"LinkedIn Connection Count on Interview vs Non-Interview Days\")\n",
    "plt.xticks([0, 1], [\"Non-Interview\", \"Interview\"])\n",
    "plt.ylabel(\"LinkedIn Connection Count\")\n",
    "plt.xlabel(\"Day Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### look at vet visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_vet_visit_day\"] = df[\"event_types\"].apply(lambda x: \"vet visit\" in x).astype(int)\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "features_to_test = [\n",
    "    \"sleep_score\", \"avg_heart_rate\", \"total_sites_visited\", \n",
    "    \"instagram_messages_sent\", \"mins_very_active\", \"sleep_hours\"\n",
    "]\n",
    "\n",
    "print(\"Feature comparison: Vet Visit vs Non-Vet Visit days\\n\")\n",
    "\n",
    "for col in features_to_test:\n",
    "    group_vet = df[df[\"is_vet_visit_day\"] == 1][col].dropna()\n",
    "    group_non = df[df[\"is_vet_visit_day\"] == 0][col].dropna()\n",
    "    \n",
    "    if len(group_vet) > 1 and len(group_non) > 1:\n",
    "        stat, p = mannwhitneyu(group_vet, group_non, alternative=\"two-sided\")\n",
    "        print(f\"{col}: p = {p:.4f} | mean (vet visit) = {group_vet.mean():.2f}, mean (non) = {group_non.mean():.2f}\")\n",
    "\n",
    "plot_features = [\"avg_heart_rate\", \"mins_very_active\", \"sleep_hours\"]\n",
    "\n",
    "for feature in plot_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=df, x=\"is_vet_visit_day\", y=feature, palette=\"Set3\")\n",
    "    sns.swarmplot(data=df, x=\"is_vet_visit_day\", y=feature, color=\".3\", alpha=0.6)\n",
    "    plt.title(f\"{feature.replace('_', ' ').title()} on Vet Visit vs Non-Vet Visit Days\")\n",
    "    plt.xticks([0, 1], [\"Non-Vet Visit\", \"Vet Visit\"])\n",
    "    plt.ylabel(feature.replace(\"_\", \" \").title())\n",
    "    plt.xlabel(\"Day Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at group lab meeting days!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_lab_meeting_day\"] = df[\"event_types\"].apply(lambda x: \"group lab meeting\" in x).astype(int)\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "features_to_test = [\n",
    "    \"sleep_score\", \"avg_heart_rate\", \"total_sites_visited\",\n",
    "    \"instagram_messages_sent\", \"mins_very_active\", \"sleep_hours\"\n",
    "]\n",
    "\n",
    "print(\"Feature comparison: Lab Meeting vs Non-Lab Meeting Days\\n\")\n",
    "\n",
    "for col in features_to_test:\n",
    "    group_lab = df[df[\"is_lab_meeting_day\"] == 1][col].dropna()\n",
    "    group_non = df[df[\"is_lab_meeting_day\"] == 0][col].dropna()\n",
    "\n",
    "    if len(group_lab) > 1 and len(group_non) > 1:\n",
    "        stat, p = mannwhitneyu(group_lab, group_non, alternative=\"two-sided\")\n",
    "        print(f\"{col}: p = {p:.4f} | mean (lab) = {group_lab.mean():.2f}, mean (non) = {group_non.mean():.2f}\")\n",
    "\n",
    "plot_features = [\"avg_heart_rate\", \"total_sites_visited\", \"instagram_messages_sent\"]\n",
    "\n",
    "for feature in plot_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=df, x=\"is_lab_meeting_day\", y=feature, palette=\"Set2\")\n",
    "    sns.swarmplot(data=df, x=\"is_lab_meeting_day\", y=feature, color=\".3\", alpha=0.6)\n",
    "    plt.title(f\"{feature.replace('_', ' ').title()} on Lab Meeting vs Non-Lab Days\")\n",
    "    plt.xticks([0, 1], [\"Non-Lab Day\", \"Lab Meeting Day\"])\n",
    "    plt.ylabel(feature.replace(\"_\", \" \").title())\n",
    "    plt.xlabel(\"Day Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now looking at deadline days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_deadline_day\"] = df[\"event_types\"].apply(lambda x: \"deadline\" in x).astype(int)\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "features_to_test = [\n",
    "    \"sleep_score\", \"avg_heart_rate\", \"total_sites_visited\",\n",
    "    \"instagram_messages_sent\", \"mins_very_active\", \"sleep_hours\"\n",
    "]\n",
    "\n",
    "print(\"Feature comparison: Deadline vs Non-Deadline Days\\n\")\n",
    "\n",
    "for col in features_to_test:\n",
    "    group_deadline = df[df[\"is_deadline_day\"] == 1][col].dropna()\n",
    "    group_non = df[df[\"is_deadline_day\"] == 0][col].dropna()\n",
    "\n",
    "    if len(group_deadline) > 1 and len(group_non) > 1:\n",
    "        stat, p = mannwhitneyu(group_deadline, group_non, alternative=\"two-sided\")\n",
    "        print(f\"{col}: p = {p:.4f} | mean (deadline) = {group_deadline.mean():.2f}, mean (non) = {group_non.mean():.2f}\")\n",
    "\n",
    "plot_features = [\"avg_heart_rate\", \"total_sites_visited\", \"sleep_score\"]\n",
    "\n",
    "for feature in plot_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=df, x=\"is_deadline_day\", y=feature, palette=\"Set1\")\n",
    "    sns.swarmplot(data=df, x=\"is_deadline_day\", y=feature, color=\".3\", alpha=0.6)\n",
    "    plt.title(f\"{feature.replace('_', ' ').title()} on Deadline vs Non-Deadline Days\")\n",
    "    plt.xticks([0, 1], [\"Non-Deadline\", \"Deadline\"])\n",
    "    plt.ylabel(feature.replace(\"_\", \" \").title())\n",
    "    plt.xlabel(\"Day Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at behavior 5 days before and after an event!\n",
    "\n",
    "# Sort df\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Get all deadline dates\n",
    "deadline_dates = df[df[\"event_types\"].apply(lambda x: \"deadline\" in x)][\"date\"]\n",
    "\n",
    "# Initialize column\n",
    "df[\"days_from_deadline\"] = None\n",
    "\n",
    "# Populate offset days around each deadline\n",
    "for deadline_day in deadline_dates:\n",
    "    for offset in range(-5, 6):  # 5 days before to 5 days after\n",
    "        day = deadline_day + pd.Timedelta(days=offset)\n",
    "        if day in df[\"date\"].values:\n",
    "            df.loc[df[\"date\"] == day, \"days_from_deadline\"] = offset\n",
    "\n",
    "# Subset to relevant window\n",
    "df_deadline_window = df[df[\"days_from_deadline\"].notna()].copy()\n",
    "df_deadline_window[\"days_from_deadline\"] = df_deadline_window[\"days_from_deadline\"].astype(int)\n",
    "\n",
    "\n",
    "# Features to include\n",
    "features = [\"sleep_hours\", \"avg_heart_rate\", \"instagram_messages_sent\", \"total_sites_visited\", \"total_steps\"]\n",
    "\n",
    "# Normalize each feature\n",
    "for col in features:\n",
    "    min_val = df_deadline_window[col].min()\n",
    "    max_val = df_deadline_window[col].max()\n",
    "    df_deadline_window[f\"{col}_norm\"] = (df_deadline_window[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Melt for seaborn\n",
    "plot_df = df_deadline_window.melt(\n",
    "    id_vars=[\"days_from_deadline\"],\n",
    "    value_vars=[f\"{col}_norm\" for col in features],\n",
    "    var_name=\"feature\",\n",
    "    value_name=\"normalized_value\"\n",
    ")\n",
    "\n",
    "# Clean up labels\n",
    "plot_df[\"feature\"] = plot_df[\"feature\"].str.replace(\"_norm\", \"\").str.replace(\"_\", \" \").str.title()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(11, 6))\n",
    "sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"days_from_deadline\",\n",
    "    y=\"normalized_value\",\n",
    "    hue=\"feature\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", lw=1.2, label=\"Deadline Day\")\n",
    "plt.title(\"Behavioral Trends Before and After Deadline Days\")\n",
    "plt.xlabel(\"Days From Deadline (0 = Deadline Day)\")\n",
    "plt.ylabel(\"Normalized Value (0–1)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(title=\"Behavior Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but for interview days\n",
    "\n",
    "# Make sure your dates are sorted\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Get all interview dates\n",
    "interview_dates = df[df[\"event_types\"].apply(lambda x: \"interview\" in x)][\"date\"]\n",
    "\n",
    "# Initialize new column\n",
    "df[\"days_from_interview\"] = None\n",
    "\n",
    "# Fill days relative to each interview date\n",
    "for interview_day in interview_dates:\n",
    "    for offset in range(-5, 6):  # 5 days before to 5 days after\n",
    "        day = interview_day + pd.Timedelta(days=offset)\n",
    "        if day in df[\"date\"].values:\n",
    "            df.loc[df[\"date\"] == day, \"days_from_interview\"] = offset\n",
    "\n",
    "# Filter for only rows within -5 to +5 days\n",
    "df_event_window = df[df[\"days_from_interview\"].notna()].copy()\n",
    "df_event_window[\"days_from_interview\"] = df_event_window[\"days_from_interview\"].astype(int)\n",
    "\n",
    "# Features to include\n",
    "features = [\"sleep_hours\", \"avg_heart_rate\", \"instagram_messages_sent\", \"total_sites_visited\", \"total_steps\"]\n",
    "\n",
    "# Normalize each column for comparability\n",
    "for col in features:\n",
    "    min_val = df_event_window[col].min()\n",
    "    max_val = df_event_window[col].max()\n",
    "    df_event_window[f\"{col}_norm\"] = (df_event_window[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "\n",
    "# Melt to long format for seaborn\n",
    "plot_df = df_event_window.melt(\n",
    "    id_vars=[\"days_from_interview\"],\n",
    "    value_vars=[f\"{col}_norm\" for col in features],\n",
    "    var_name=\"feature\",\n",
    "    value_name=\"normalized_value\"\n",
    ")\n",
    "\n",
    "# Clean up feature names\n",
    "plot_df[\"feature\"] = plot_df[\"feature\"].str.replace(\"_norm\", \"\").str.replace(\"_\", \" \").str.title()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(11, 6))\n",
    "sns.lineplot(\n",
    "    data=plot_df,\n",
    "    x=\"days_from_interview\",\n",
    "    y=\"normalized_value\",\n",
    "    hue=\"feature\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", lw=1.2, label=\"Interview Day\")\n",
    "plt.title(\"Behavioral Trends Before and After Interview Days\")\n",
    "plt.xlabel(\"Days From Interview (0 = Interview Day)\")\n",
    "plt.ylabel(\"Normalized Value (0–1)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(title=\"Behavior Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_winter_break\"] = df[\"event_types\"].apply(lambda x: \"winter break\" in x).astype(int)\n",
    "\n",
    "features = [\n",
    "    \"sleep_score\", \"sleep_hours\", \"avg_heart_rate\", \"total_sites_visited\",\n",
    "    \"instagram_messages_sent\", \"mins_very_active\", \"total_steps\"\n",
    "]\n",
    "\n",
    "df.groupby(\"is_winter_break\")[features].mean().T\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "print(\"Behavior Comparison: Winter Break vs Non-Break Days\\n\")\n",
    "\n",
    "for col in features:\n",
    "    break_days = df[df[\"is_winter_break\"] == 1][col].dropna()\n",
    "    non_break_days = df[df[\"is_winter_break\"] == 0][col].dropna()\n",
    "\n",
    "    if len(break_days) > 1 and len(non_break_days) > 1:\n",
    "        stat, p = mannwhitneyu(break_days, non_break_days, alternative='two-sided')\n",
    "        print(f\"{col}: p = {p:.4f}, mean (break) = {break_days.mean():.2f}, mean (non) = {non_break_days.mean():.2f}\")\n",
    "\n",
    "\n",
    "plot_features = [\"sleep_hours\", \"total_sites_visited\", \"instagram_messages_sent\"]\n",
    "\n",
    "for feature in plot_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=df, x=\"is_winter_break\", y=feature, palette=\"Set2\")\n",
    "    sns.swarmplot(data=df, x=\"is_winter_break\", y=feature, color=\".3\", alpha=0.6)\n",
    "    plt.title(f\"{feature.replace('_', ' ').title()} During vs Outside Winter Break\")\n",
    "    plt.xticks([0, 1], [\"Non-Break\", \"Winter Break\"])\n",
    "    plt.ylabel(feature.replace(\"_\", \" \").title())\n",
    "    plt.xlabel(\"Day Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips\n",
    "\n",
    "\n",
    "df[\"is_trip\"] = df[\"event_types\"].apply(lambda x: \"trip\" in x).astype(int)\n",
    "\n",
    "features = [\n",
    "    \"sleep_score\", \"sleep_hours\", \"avg_heart_rate\", \"total_sites_visited\",\n",
    "    \"instagram_messages_sent\", \"mins_very_active\", \"total_steps\"\n",
    "]\n",
    "\n",
    "df.groupby(\"is_trip\")[features].mean().T\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "print(\"Behavior Comparison: Trip vs Non-trip Days\\n\")\n",
    "\n",
    "for col in features:\n",
    "    break_days = df[df[\"is_trip\"] == 1][col].dropna()\n",
    "    non_break_days = df[df[\"is_trip\"] == 0][col].dropna()\n",
    "\n",
    "    if len(break_days) > 1 and len(non_break_days) > 1:\n",
    "        stat, p = mannwhitneyu(break_days, non_break_days, alternative='two-sided')\n",
    "        print(f\"{col}: p = {p:.4f}, mean (trip) = {break_days.mean():.2f}, mean (non) = {non_break_days.mean():.2f}\")\n",
    "\n",
    "\n",
    "plot_features = [\"sleep_hours\", \"total_sites_visited\", \"instagram_messages_sent\"]\n",
    "\n",
    "for feature in plot_features:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=df, x=\"is_trip\", y=feature, palette=\"Set2\")\n",
    "    sns.swarmplot(data=df, x=\"is_trip\", y=feature, color=\".3\", alpha=0.6)\n",
    "    plt.title(f\"{feature.replace('_', ' ').title()} During vs Outside Trips\")\n",
    "    plt.xticks([0, 1], [\"Non-Trip\", \"Trip\"])\n",
    "    plt.ylabel(feature.replace(\"_\", \" \").title())\n",
    "    plt.xlabel(\"Day Type\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_data_with_events.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map event_types to specific labels\n",
    "def get_break_label(event_list):\n",
    "    if \"summer\" in event_list:\n",
    "        return \"summer\"\n",
    "    elif \"fall\" in event_list:\n",
    "        return \"fall\"\n",
    "    elif \"winter break\" in event_list:\n",
    "        return \"winter\"\n",
    "    else:\n",
    "        return None  # exclude non-break days\n",
    "\n",
    "df[\"target_event\"] = df[\"event_types\"].apply(get_break_label)\n",
    "\n",
    "# Filter to rows that are one of the 3 break types\n",
    "df_multi = df[df[\"target_event\"].notna()].copy()\n",
    "\n",
    "# Confirm label distribution\n",
    "print(df_multi[\"target_event\"].value_counts())\n",
    "\n",
    "features = [\n",
    "    \"sleep_score\", \"sleep_hours\", \"avg_heart_rate\", \"total_sites_visited\",\n",
    "    \"mins_very_active\", \"instagram_messages_sent\", \"instagram_liked_posts_count\",\n",
    "    \"linkedin_connection_count\", \"linkedin_message_count\", \"total_steps\"\n",
    "]\n",
    "\n",
    "df_multi = df_multi.dropna(subset=features + [\"target_event\"])\n",
    "X = df_multi[features]\n",
    "y = df_multi[\"target_event\"]\n",
    "\n",
    "clf = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=cv, scoring=\"f1_weighted\")\n",
    "\n",
    "print(\"Cross-validated F1 (weighted) scores:\", scores)\n",
    "print(\"Mean F1 score: {:.4f}\".format(scores.mean()))\n",
    "\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(clf.feature_importances_, index=features).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=importances.values, y=importances.index, palette=\"viridis\")\n",
    "plt.title(\"Feature Importance for Predicting Break Type\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report (Multi-Class, Test Set):\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Season Classification\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now just fall vs summer - BINARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fall_summer_label(event_list):\n",
    "    if \"summer\" in event_list:\n",
    "        return \"summer\"\n",
    "    elif \"fall\" in event_list:\n",
    "        return \"fall\"\n",
    "    else:\n",
    "        return None  # exclude non-summer/fall rows\n",
    "\n",
    "df[\"target_event\"] = df[\"event_types\"].apply(get_fall_summer_label)\n",
    "\n",
    "# Keep only summer/fall\n",
    "df_binary = df[df[\"target_event\"].notna()].copy()\n",
    "\n",
    "# Check distribution\n",
    "print(df_binary[\"target_event\"].value_counts())\n",
    "\n",
    "features = [\n",
    "    \"sleep_score\", \"sleep_hours\", \"avg_heart_rate\", \"total_sites_visited\",\n",
    "    \"mins_very_active\", \"instagram_messages_sent\", \"instagram_liked_posts_count\",\n",
    "    \"linkedin_connection_count\", \"linkedin_message_count\", \"total_steps\"\n",
    "]\n",
    "\n",
    "df_binary = df_binary.dropna(subset=features + [\"target_event\"])\n",
    "X = df_binary[features]\n",
    "y = df_binary[\"target_event\"]\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=cv, scoring=\"f1_weighted\")\n",
    "\n",
    "print(\"Cross-validated F1 (weighted) scores:\", scores)\n",
    "print(\"Mean F1 score: {:.4f}\".format(scores.mean()))\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "importances = pd.Series(clf.feature_importances_, index=features).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=importances.values, y=importances.index, palette=\"viridis\")\n",
    "plt.title(\"Feature Importance for Predicting Fall vs Summer Break\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report (Fall vs Summer):\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot(cmap=\"Blues\", values_format='d')\n",
    "plt.title(\"Season Classification\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML-IA-class)",
   "language": "python",
   "name": "ml-ia-class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
